{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c89773e-d84a-4974-84e1-2fb75e7afacd",
   "metadata": {},
   "source": [
    "# Appendix III: Webscraping the Library of Congress Catalog\n",
    "\n",
    "This code uses the emailed catalog records, saved as text files, to retrieve the permalinks for the Library of Congress catalog entries. The permalinks are then used to obtain genre/form descriptions from the Library of Congress catalog, looping over all included permalinks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea112bf0-edc3-4832-bbdd-5d5bea103c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4 #this may be appendices only\n",
    "import requests #this may be appendices only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from   sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from   sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee5e0a0-6f3d-447b-8cdb-6b85d67936e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='LOC Email Data.txt' mode='r' encoding='utf8'>\n",
      "<_io.TextIOWrapper name='LOC Email Data2.txt' mode='r' encoding='utf8'>\n",
      "<_io.TextIOWrapper name='LOC Email Data3.txt' mode='r' encoding='utf8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get LOC Permalinks from email text\n",
    "#ISBNs entered into the advanced search in LC Catalog in groups of 85 - 170. Results can be emailed/exported in batches of 100\n",
    "#most searches resulted in less than 150 records\n",
    "#text formatted results from each export were copied into a single text document for a round of searching, and then the text processed to retrieve the permalinks to the LC records\n",
    "#Multiple rounds of searches were run. The first round resulted in approximately 450 non-successes, the second in slightly less than 100 non-successes, and the third resulted in only 80 unmatched records.\n",
    "\n",
    "loc_email=open(\"LOC Email Data.txt\",encoding='utf8')\n",
    "print(loc_email)\n",
    "link_lst1 = []\n",
    "\n",
    "for ln in loc_email:\n",
    "    if ln.lstrip().startswith('Permalink'): #find permalink rows of text\n",
    "        link_lst1.append(ln.lstrip().rstrip('\\n')[12:]) #remove \"Permalink: \" from the string, retain only the actual link\n",
    "\n",
    "loc_email.close()\n",
    "\n",
    "loc_email=open(\"LOC Email Data2.txt\",encoding='utf8')\n",
    "print(loc_email)\n",
    "link_lst2 = []\n",
    "\n",
    "for ln in loc_email:\n",
    "    if ln.lstrip().startswith('Permalink'):\n",
    "        link_lst2.append(ln.lstrip().rstrip('\\n')[12:])\n",
    "\n",
    "loc_email.close()\n",
    "\n",
    "loc_email=open(\"LOC Email Data3.txt\",encoding='utf8')\n",
    "print(loc_email)\n",
    "link_lst3 = []\n",
    "\n",
    "for ln in loc_email:\n",
    "    if ln.lstrip().startswith('Permalink'):\n",
    "        link_lst3.append(ln.lstrip().rstrip('\\n')[12:])\n",
    "loc_email.close()\n",
    "\n",
    "link_lst=list(set(link_lst1 + link_lst2 + link_lst3))#concatenate all lists of links into a single list to loop over for webscraping.\n",
    "len(link_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6568f-fac5-41d9-8475-c828724833f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_loop_results = []\n",
    "link_lst= list(set(link_lst)) #remove duplicate permalinks, as each search round may have resulted in overlaps\n",
    "k_range = len(link_lst)\n",
    "for k in range(0,k_range):\n",
    "    loc_req = requests.get(link_lst[k])\n",
    "    soup_hold = bs4.BeautifulSoup(loc_req.text,'html.parser')\n",
    "    item_title_hold=soup_hold.findAll('h3',attrs={'class':'item-title'}) #class names are very limited on the LC catalog pages, which offers flexibility in webpage creation, but makes specifying a particular item title difficult.\n",
    "    title_genre_list=[] #the form/genres associated with an LC record can be an n-dimensional array \n",
    "    results_holder = [] #not used in the final version of this loop, temporary step in loop development\n",
    "    for i in range(0,len(item_title_hold)):\n",
    "        item_title_i = item_title_hold[i]\n",
    "        if item_title_i.string=='ISBN': #find the ISBN item-title\n",
    "            parent_div = item_title_i.parent #look at all parts in the associated div - due to webpage structure, the actual value of the ISBN isn't stored with the ISBN title\n",
    "            isbn_field = parent_div.h3.next_sibling.next_sibling.li.span.string[0:13] #two siblings below the ISBN is the <span> tag that contains the ISBNs associated with the record. This code chooses the first ISBN and assumes it is an ISBN 13\n",
    "        if item_title_i.string == 'Form/Genre':\n",
    "            parent_div = item_title_i.parent\n",
    "            for j in parent_div.findAll('span'):\n",
    "                title_genre_list.append(j.string)\n",
    "            results_holder.append((isbn_field,title_genre_list)) #this will be emptied out for each iteration of the outer loop. \n",
    "    outer_loop_results.append((link_lst[k],isbn_field,title_genre_list))\n",
    "print('Done')\n",
    "loc_results = pd.DataFrame(outer_loop_results, columns = ['permalink','isbn','genres'])\n",
    "loc_results.head()\n",
    "\n",
    "#Find cases where the ISBN 13 assumption is invalid by identifying cases where a non-numeric character is in the isbn field\n",
    "\n",
    "loc_results = pd.DataFrame(outer_loop_results, columns = ['permalink','isbn','genres'])\n",
    "loc_results.head()\n",
    "loc_results.isbn.astype(str)\n",
    "loc_results[loc_results.isbn.str.isdigit()==False]\n",
    "\n",
    "loc_results.to_csv('C:/Users/Aryn/Documents/GitHub/INFO2950/Phase V/loc_results_v2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
